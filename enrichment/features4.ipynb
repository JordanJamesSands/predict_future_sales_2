{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a DF relating item category name and shop name to shop ids and item ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ENCODING_NPERM = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../gen_data/train2.csv')\n",
    "\n",
    "y_train_list = pickle.load(open('../gen_data/y_train--features1.ipynb--.pickle','rb'))\n",
    "x_train_list = pickle.load(open('../gen_data/x_train--features3.ipynb--.pickle','rb'))\n",
    "x_test_list = pickle.load(open('../gen_data/x_test--features3.ipynb--.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 70)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse City data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_encoder = preprocessing.LabelEncoder()\n",
    "cities_series = pd.Series([re.search('(.*?) ',n).group() for n in df.shop_name],index=df.index)\n",
    "cities_encoder.fit(cities_series)\n",
    "df['city'] = cities_encoder.transform(cities_series)\n",
    "del cities_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse item category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_type_encoder = preprocessing.LabelEncoder()\n",
    "item_type_series = df.item_category_name.map(lambda x: re.split('-',x)[0])\n",
    "item_type_encoder.fit(item_type_series)\n",
    "df['item_type'] = item_type_encoder.transform(item_type_series)\n",
    "del item_type_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse more item_category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_encoder = preprocessing.LabelEncoder()\n",
    "item_info_series = df.item_category_name.map(lambda x: '-'.join(re.split('-',x)[1:]) if len(re.split('-',x))>1 else 'NAN')\n",
    "item_info_encoder.fit(item_info_series)\n",
    "df['item_info'] = item_info_encoder.transform(item_info_series)\n",
    "del item_info_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select relevant columns in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['shop_id','item_id','item_category_id','city','item_type','item_info']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to downcast data types to 32 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    float_cols = [col for col in df if df[col].dtype=='float64']\n",
    "    int_cols = [col for col in df if df[col].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = downcast(df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data above into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(lambda x: x.merge(df,on=['item_id','item_category_id','shop_id'],how='left'),x_train_list))\n",
    "x_test_list = list(map(lambda x: x.merge(df,on=['item_id','item_category_id','shop_id'],how='left'),x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding is based on historical information, available for both train and test datasets, as such, we needn't worry about regularisation specifically for target encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode(x_train,y_train,x_test,cols,nperms):\n",
    "    x_train['target'] = y_train\n",
    "    print('top: '+str(x_train.shape))\n",
    "#for test data\n",
    "    for col in cols:\n",
    "        agged_sum = x_train.groupby(col).target.sum()\n",
    "        x_test[col+'_encoded'] = x_test[col].map(agged_sum)\n",
    "        x_test[col+'_encoded'].fillna(0,inplace=True)\n",
    "            \n",
    "#for train data, need to regularise\n",
    "    for col in cols:\n",
    "        print('Encoding '+col+':')\n",
    "        encoding_df = pd.DataFrame()\n",
    "        for perm_num in range(0,nperms):\n",
    "            print('\\tComputing encoding on permutation '+str(perm_num)+' of '+str(nperms))\n",
    "            #set random state to perm num for reproducibility\n",
    "            #make this faster by just changing index?\n",
    "            perm_x_train = x_train.sample(frac=1,random_state=perm_num)\n",
    "            print('mid, perm: '+str(perm_x_train.shape))\n",
    "            cumsum   = perm_x_train.groupby(col).target.cumsum() - perm_x_train.target\n",
    "            cumcount = perm_x_train.groupby(col).target.cumcount()\n",
    "            encoding = cumsum/cumcount\n",
    "            \n",
    "            #encoding_df = pd.concat([],axis=1)\n",
    "            encoding_df['perm_'+str(perm_num)+'_encoding'] = encoding\n",
    "            \n",
    "        encoding_df['colmeans'] = encoding_df.mean(axis=1)    \n",
    "        x_train[col+'_encoded'] = encoding_df.colmeans\n",
    "        x_train[col+'_encoded'].fillna(0,inplace=True)\n",
    "        print('later: '+str(x_train.shape))\n",
    "        del encoding_df\n",
    "        gc.collect()\n",
    "    print('returning'+str(x_train.shape))\n",
    "    return x_train.drop('target',axis=1) , x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top: (6186922, 74)\n",
      "Encoding shop_id:\n",
      "\tComputing encoding on permutation 0 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 1 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 2 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 3 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 4 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 5 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 6 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "\tComputing encoding on permutation 7 of 8\n",
      "mid, perm: (6186922, 74)\n",
      "later: (6186922, 75)\n",
      "returning(6186922, 75)\n",
      "top: (6425094, 74)\n",
      "Encoding shop_id:\n",
      "\tComputing encoding on permutation 0 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 1 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 2 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 3 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 4 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 5 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 6 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "\tComputing encoding on permutation 7 of 8\n",
      "mid, perm: (6425094, 74)\n",
      "later: (6425094, 75)\n",
      "returning(6425094, 75)\n"
     ]
    }
   ],
   "source": [
    "to_target_encode = ['shop_id','item_id','item_category_id','month','city','item_type','item_info']\n",
    "to_target_encode=['shop_id']\n",
    "jumbled_list = [target_encode(x_train,y_train,x_test,to_target_encode,TARGET_ENCODING_NPERM) for x_train , y_train, x_test in zip(x_train_list,y_train_list,x_test_list)]\n",
    "x_train_list , x_test_list = list(map(list,zip(*jumbled_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 74)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 74)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 74)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add bool: item never sold before\n",
    "                    #shop never sold before\n",
    "# and int: num item sold\n",
    "# num shop sold\n",
    "# FOR EACH MONTH\n",
    "\n",
    "#this is target encoding filling nans with 0 except missing early data\n",
    "\n",
    "#doing this early in pipeline would be easy\n",
    "\n",
    "#going back for all time might be a bad idea, the nature of the data would change thru time, (summingup)\n",
    "#instaed just use dateback range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variables to quantify how much we know about a data point\n",
    "#For each shop_id and item_id create sum of recent history(total sales for dateback_range)\n",
    "#create bool if 0 indicating new shop or item\n",
    "def generate_recent_history_summary(df):\n",
    "    df_items = df.filter(regex='sum_item_sales_back_\\d+$')\n",
    "    df['historical_item_sales'] = df_items.sum(axis=1)\n",
    "    df['new_item'] = (df.historical_item_sales<0.5)*1\n",
    "    \n",
    "    df_shops = df.filter(regex='sum_shop_sales_back_\\d+$')\n",
    "    df['historical_shop_sales'] = df_shops.sum(axis=1)\n",
    "    df['new_shop'] = (df.historical_shop_sales<0.5)*1\n",
    "    \n",
    "    df_item_cats = df.filter(regex='sum_item_cat_sales_back_\\d+$')\n",
    "    df['historical_item_cat_sales'] = df_item_cats.sum(axis=1)\n",
    "    df['new_item_cat'] = (df.historical_item_cat_sales<0.5)*1\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(generate_recent_history_summary,x_train_list))\n",
    "x_test_list = list(map(generate_recent_history_summary,x_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>historical_item_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>482</td>\n",
       "      <td>1097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>485</td>\n",
       "      <td>818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>804</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>839</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1007</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1406</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1407</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1412</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1413</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1414</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1415</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1416</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1439</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1441</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1449</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1460</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1467</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1471</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1495</td>\n",
       "      <td>1425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1502</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1511</td>\n",
       "      <td>1446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1512</td>\n",
       "      <td>1532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1514</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1799</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1809</td>\n",
       "      <td>1346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1811</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186892</th>\n",
       "      <td>14430</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186893</th>\n",
       "      <td>15971</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186894</th>\n",
       "      <td>16055</td>\n",
       "      <td>724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186895</th>\n",
       "      <td>16084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186896</th>\n",
       "      <td>16179</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186897</th>\n",
       "      <td>16243</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186898</th>\n",
       "      <td>16540</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186899</th>\n",
       "      <td>18715</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186900</th>\n",
       "      <td>19501</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186901</th>\n",
       "      <td>19745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186902</th>\n",
       "      <td>19789</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186903</th>\n",
       "      <td>19885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186904</th>\n",
       "      <td>20070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186905</th>\n",
       "      <td>6400</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186906</th>\n",
       "      <td>9150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186907</th>\n",
       "      <td>9496</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186908</th>\n",
       "      <td>9949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186909</th>\n",
       "      <td>13379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186910</th>\n",
       "      <td>13521</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186911</th>\n",
       "      <td>15443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186912</th>\n",
       "      <td>16729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186913</th>\n",
       "      <td>18024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186914</th>\n",
       "      <td>20267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186915</th>\n",
       "      <td>4608</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186916</th>\n",
       "      <td>4779</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186917</th>\n",
       "      <td>10656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186918</th>\n",
       "      <td>14899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186919</th>\n",
       "      <td>18577</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186920</th>\n",
       "      <td>21459</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186921</th>\n",
       "      <td>22043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6186922 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id  historical_item_sales\n",
       "0             32                    0.0\n",
       "1             33                  118.0\n",
       "2             99                    0.0\n",
       "3            482                 1097.0\n",
       "4            485                  818.0\n",
       "5            804                  144.0\n",
       "6            839                  307.0\n",
       "7           1007                  463.0\n",
       "8           1406                   16.0\n",
       "9           1407                  726.0\n",
       "10          1412                   71.0\n",
       "11          1413                   35.0\n",
       "12          1414                   44.0\n",
       "13          1415                    0.0\n",
       "14          1416                  144.0\n",
       "15          1439                    0.0\n",
       "16          1441                  140.0\n",
       "17          1449                  116.0\n",
       "18          1460                  329.0\n",
       "19          1467                  294.0\n",
       "20          1471                  428.0\n",
       "21          1480                    0.0\n",
       "22          1495                 1425.0\n",
       "23          1502                  699.0\n",
       "24          1511                 1446.0\n",
       "25          1512                 1532.0\n",
       "26          1514                  324.0\n",
       "27          1799                   63.0\n",
       "28          1809                 1346.0\n",
       "29          1811                  785.0\n",
       "...          ...                    ...\n",
       "6186892    14430                    0.0\n",
       "6186893    15971                    0.0\n",
       "6186894    16055                  724.0\n",
       "6186895    16084                    0.0\n",
       "6186896    16179                   11.0\n",
       "6186897    16243                    0.0\n",
       "6186898    16540                    0.0\n",
       "6186899    18715                   11.0\n",
       "6186900    19501                    0.0\n",
       "6186901    19745                    0.0\n",
       "6186902    19789                   16.0\n",
       "6186903    19885                    0.0\n",
       "6186904    20070                    0.0\n",
       "6186905     6400                   92.0\n",
       "6186906     9150                    0.0\n",
       "6186907     9496                   13.0\n",
       "6186908     9949                    0.0\n",
       "6186909    13379                    0.0\n",
       "6186910    13521                  157.0\n",
       "6186911    15443                    0.0\n",
       "6186912    16729                    0.0\n",
       "6186913    18024                    0.0\n",
       "6186914    20267                    0.0\n",
       "6186915     4608                    0.0\n",
       "6186916     4779                   14.0\n",
       "6186917    10656                    0.0\n",
       "6186918    14899                    0.0\n",
       "6186919    18577                    3.0\n",
       "6186920    21459                    0.0\n",
       "6186921    22043                    0.0\n",
       "\n",
       "[6186922 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0][['item_id','historical_item_sales']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_train_list,open('../gen_data/x_train--features4.ipynb--.pickle','wb'))\n",
    "pickle.dump(x_test_list,open('../gen_data/x_test--features4.ipynb--.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_train_list[0][['date_block_num','item_id','item_id_encoded','historical_item_sales']].copy()\n",
    "df.columns = ['date_block_num','item_id','ORIGINAL_item_id_encoded','historical_item_sales']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work on this\n",
    "#this isnt working properly, drop it, I have almost the same information from elsewhere\n",
    "def old_target_encode(df,target,cols,fillna=0):\n",
    "    maxmonth = df.date_block_num.max()\n",
    "    print(maxmonth)\n",
    "    df['target'] = target\n",
    "    for col in cols:\n",
    "        print('Encoding variable: '+col)\n",
    "        #dont use current data, that way we can do this for both train and test sets\n",
    "        agged_targ = df[df.date_block_num<maxmonth].groupby(col).target.sum()\n",
    "        agged_targ = df[(df.date_block_num<maxmonth) & (df.date_block_num>=(maxmonth-12))].groupby(col).target.sum()\n",
    "        #agged_targ = df[df.date_block_num>20].groupby(col).target.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        df[col+'_encoded'] = df[col].map(agged_targ)\n",
    "        if fillna=='mean':\n",
    "            df[col].fillna(df(col).mean(),inplace=True)\n",
    "        elif fillna=='median':\n",
    "            df[col].fillna(df(col).median(),inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(0,inplace=True)\n",
    "    return df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Im counting back the months from max month, but historical is rolling for each date, historical is bad becuase it double counts, or does it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = y_train_list[0]\n",
    "target_encode(df,targs,['item_id'])\n",
    "g = df[(df.date_block_num<32) & (df.date_block_num>=20)].groupby('item_id').target.sum()\n",
    "df['item_id_encoded_manual'] = df.item_id.map(g)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21 ... 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_train_list[1]\n",
    "targs = y_train_list[1]\n",
    "df['target'] = targs\n",
    "df_small = df[['item_id','item_id_encoded','target','historical_item_sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby('item_id').target.sum()\n",
    "g.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['item_id_encoded_manual'] = df.item_id.map(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.item_id==32)].target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['item_id','item_idencoded']].sort_values('item_id').head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 = df.sample(100)\n",
    "df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
